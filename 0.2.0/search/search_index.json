{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MOYA - Meta Orchestration framework for Your Agents","text":"<p>MOYA is a reference implementation of our research paper titled \"Engineering LLM Powered Multi-agent Framework for Autonomous CloudOps\". The framework provides a flexible and extensible architecture for creating, managing, and orchestrating multiple AI agents to handle various tasks autonomously.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Agent Management: Create, register, and manage multiple AI agents.</li> <li>Orchestration: Orchestrate conversations and tasks across multiple agents.</li> <li>Memory Tools: Integrate memory tools to maintain conversation context and history.</li> <li>Streaming Responses: Support for streaming responses from agents.</li> <li>Extensibility: Easily extend the framework with new agents, tools, and orchestrators.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Check out our Installation Guide and Quick Start Examples to begin using MOYA.</p>"},{"location":"concepts/agents/","title":"Agent Concepts","text":""},{"location":"concepts/agents/#agents-api-reference","title":"Agents API Reference","text":"<p>This section provides detailed API documentation for MOYA's agent implementations.</p>"},{"location":"concepts/agents/#base-agent","title":"Base Agent","text":""},{"location":"concepts/agents/#moya.agents.base_agent","title":"<code>moya.agents.base_agent</code>","text":"<p>Base Agent interface for Moya.</p> <p>This module defines the abstract Agent class, which describes the behavior and interface that all agents in Moya must follow.</p> <p>Agents can: - Provide a textual 'description' of their capabilities, - Expose an 'agent_type' to facilitate registry logic, - Initialize themselves with 'setup()', - Handle incoming messages via 'handle_message()', - Dynamically call external tools via 'call_tool()', - Discover available tools via 'discover_tools()', - Optionally retrieve conversation memory (summary, last n messages)   through a MemoryTool if registered in the tool registry.</p>"},{"location":"concepts/agents/#moya.agents.base_agent.Agent","title":"<code>Agent</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for all Moya agents.</p> <p>Agents are responsible for: - A textual description of their capabilities (description property), - A type descriptor (agent_type) that helps the registry handle them, - Any necessary setup or initialization (setup()), - Receiving messages or prompts (handle_message()), - Generating responses (usually via an LLM or other logic), - Optionally discovering &amp; calling tools (call_tool, discover_tools).</p> <p>Concrete implementations (e.g., OpenAIAgent, AnthropicAgent, RemoteAgent) should override the abstract methods with vendor or application-specific logic.</p> Source code in <code>moya/agents/base_agent.py</code> <pre><code>class Agent(abc.ABC):\n    \"\"\"\n    Abstract base class for all Moya agents.\n\n    Agents are responsible for:\n    - A textual description of their capabilities (description property),\n    - A type descriptor (agent_type) that helps the registry handle them,\n    - Any necessary setup or initialization (setup()),\n    - Receiving messages or prompts (handle_message()),\n    - Generating responses (usually via an LLM or other logic),\n    - Optionally discovering &amp; calling tools (call_tool, discover_tools).\n\n    Concrete implementations (e.g., OpenAIAgent, AnthropicAgent, RemoteAgent)\n    should override the abstract methods with vendor or application-specific logic.\n    \"\"\"\n\n    def __init__(\n        self,\n        config: AgentConfig\n    ):\n        \"\"\"\n        Initialize the agent with:\n          - a name (agent_name),\n          - an agent type (agent_type) for registry usage,\n          - a brief description of its capabilities/role,\n          - an optional config dictionary (API keys, model parameters, etc.),\n          - an optional reference to a tool registry.\n\n        :param agent_name: A unique name or identifier for the agent.\n        :param agent_type: A short string representing the type of the agent\n                           (e.g., \"BaseAgent\", \"RemoteAgent\", \"OpenAIAgent\").\n        :param description: A brief explanation of the agent's capabilities and role.\n        :param config: Optional configuration dict (e.g., API keys, parameters).\n        :param agent_config: Optional AgentConfig object with model parameters.\n        :param tool_registry: A reference to a centralized ToolRegistry (if any).\n        \"\"\"\n        self.agent_name = config.agent_name\n        self.agent_type = config.agent_type\n        self.description = config.description\n        self.llm_config = config.llm_config or {}\n        self.tool_registry = config.tool_registry\n        self.system_prompt = config.system_prompt or \"You are a helpful AI assistant.\"\n        self.memory = config.memory\n        self.is_tool_caller = config.is_tool_caller\n        self.is_streaming = config.is_streaming\n\n\n    @abc.abstractmethod\n    def handle_message(self, message: str, **kwargs) -&gt; str:\n        \"\"\"\n        Receive a message (prompt) and generate a response.\n\n        :param message: The user or system prompt to be handled.\n        :param kwargs: Additional context or parameters the agent might need,\n                       such as conversation ID, user metadata, etc.\n        :return: The agent's response as a string.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement handle_message().\")\n\n    @abc.abstractmethod\n    def handle_message_stream(self, message: str, **kwargs):\n        \"\"\"\n        Receive a message (prompt) and generate a response in a streaming fashion.\n\n        :param message: The user or system prompt to be handled.\n        :param kwargs: Additional context or parameters the agent might need,\n                       such as conversation ID, user metadata, etc.\n        :yield: Chunks of the agent's response as strings.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement handle_message_stream().\")\n\n    def call_tool(self, tool_name: str, method_name: str, *args, **kwargs) -&gt; Any:\n        \"\"\"\n        Call a method on a registered tool by name.\n\n        :param tool_name: The unique name or identifier of the tool.\n        :param method_name: The name of the method to call on the tool.\n        :param args: Positional arguments to pass to the tool method.\n        :param kwargs: Keyword arguments to pass to the tool method.\n        :return: The result of the tool method call.\n        \"\"\"\n        if not self.tool_registry:\n            raise RuntimeError(\n                f\"Agent '{self.agent_name}' has no tool registry attached.\"\n            )\n\n        tool = self.tool_registry.get_tool(tool_name)\n        if not tool:\n            raise ValueError(\n                f\"No tool named '{tool_name}' found in the registry.\"\n            )\n\n        method = getattr(tool, method_name, None)\n        if not callable(method):\n            raise AttributeError(\n                f\"Tool '{tool_name}' does not have method '{method_name}'.\"\n            )\n\n        return method(*args, **kwargs)\n\n    def discover_tools(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of available tool names from the registry.\n\n        :return: A list of tool names (strings).\n        \"\"\"\n        if not self.tool_registry:\n            return []\n        return self.tool_registry.list_tools()\n\n    def get_conversation_summary(self, thread_id: str) -&gt; str:\n        \"\"\"\n        Retrieve a summary of the conversation so far using the MemoryTool, if available.\n\n        :param thread_id: The identifier of the conversation thread.\n        :return: A textual summary of the conversation so far. If no MemoryTool\n                 or no registry is found, returns an empty string or raises an error.\n        \"\"\"        \n        if not self.memory:\n            return \"\"\n        return self.memory.get_conversation_summary(thread_id)\n\n    def get_last_n_messages(self, thread_id: str, n: int = 5) -&gt; List[Any]:\n        \"\"\"\n        Retrieve the last n messages of the conversation using the MemoryTool, if available.\n\n        :param thread_id: The identifier of the conversation thread.\n        :param n: The number of recent messages to retrieve.\n        :return: A list of message objects or dictionaries.\n        \"\"\"\n        if not self.memory:\n            return \"\"\n        return self.memory.get_last_n_messages(thread_id, n)\n</code></pre>"},{"location":"concepts/agents/#moya.agents.base_agent.Agent.__init__","title":"<code>__init__(config)</code>","text":"Initialize the agent with <ul> <li>a name (agent_name),</li> <li>an agent type (agent_type) for registry usage,</li> <li>a brief description of its capabilities/role,</li> <li>an optional config dictionary (API keys, model parameters, etc.),</li> <li>an optional reference to a tool registry.</li> </ul> <p>:param agent_name: A unique name or identifier for the agent. :param agent_type: A short string representing the type of the agent                    (e.g., \"BaseAgent\", \"RemoteAgent\", \"OpenAIAgent\"). :param description: A brief explanation of the agent's capabilities and role. :param config: Optional configuration dict (e.g., API keys, parameters). :param agent_config: Optional AgentConfig object with model parameters. :param tool_registry: A reference to a centralized ToolRegistry (if any).</p> Source code in <code>moya/agents/base_agent.py</code> <pre><code>def __init__(\n    self,\n    config: AgentConfig\n):\n    \"\"\"\n    Initialize the agent with:\n      - a name (agent_name),\n      - an agent type (agent_type) for registry usage,\n      - a brief description of its capabilities/role,\n      - an optional config dictionary (API keys, model parameters, etc.),\n      - an optional reference to a tool registry.\n\n    :param agent_name: A unique name or identifier for the agent.\n    :param agent_type: A short string representing the type of the agent\n                       (e.g., \"BaseAgent\", \"RemoteAgent\", \"OpenAIAgent\").\n    :param description: A brief explanation of the agent's capabilities and role.\n    :param config: Optional configuration dict (e.g., API keys, parameters).\n    :param agent_config: Optional AgentConfig object with model parameters.\n    :param tool_registry: A reference to a centralized ToolRegistry (if any).\n    \"\"\"\n    self.agent_name = config.agent_name\n    self.agent_type = config.agent_type\n    self.description = config.description\n    self.llm_config = config.llm_config or {}\n    self.tool_registry = config.tool_registry\n    self.system_prompt = config.system_prompt or \"You are a helpful AI assistant.\"\n    self.memory = config.memory\n    self.is_tool_caller = config.is_tool_caller\n    self.is_streaming = config.is_streaming\n</code></pre>"},{"location":"concepts/agents/#moya.agents.base_agent.Agent.call_tool","title":"<code>call_tool(tool_name, method_name, *args, **kwargs)</code>","text":"<p>Call a method on a registered tool by name.</p> <p>:param tool_name: The unique name or identifier of the tool. :param method_name: The name of the method to call on the tool. :param args: Positional arguments to pass to the tool method. :param kwargs: Keyword arguments to pass to the tool method. :return: The result of the tool method call.</p> Source code in <code>moya/agents/base_agent.py</code> <pre><code>def call_tool(self, tool_name: str, method_name: str, *args, **kwargs) -&gt; Any:\n    \"\"\"\n    Call a method on a registered tool by name.\n\n    :param tool_name: The unique name or identifier of the tool.\n    :param method_name: The name of the method to call on the tool.\n    :param args: Positional arguments to pass to the tool method.\n    :param kwargs: Keyword arguments to pass to the tool method.\n    :return: The result of the tool method call.\n    \"\"\"\n    if not self.tool_registry:\n        raise RuntimeError(\n            f\"Agent '{self.agent_name}' has no tool registry attached.\"\n        )\n\n    tool = self.tool_registry.get_tool(tool_name)\n    if not tool:\n        raise ValueError(\n            f\"No tool named '{tool_name}' found in the registry.\"\n        )\n\n    method = getattr(tool, method_name, None)\n    if not callable(method):\n        raise AttributeError(\n            f\"Tool '{tool_name}' does not have method '{method_name}'.\"\n        )\n\n    return method(*args, **kwargs)\n</code></pre>"},{"location":"concepts/agents/#moya.agents.base_agent.Agent.discover_tools","title":"<code>discover_tools()</code>","text":"<p>Return a list of available tool names from the registry.</p> <p>:return: A list of tool names (strings).</p> Source code in <code>moya/agents/base_agent.py</code> <pre><code>def discover_tools(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of available tool names from the registry.\n\n    :return: A list of tool names (strings).\n    \"\"\"\n    if not self.tool_registry:\n        return []\n    return self.tool_registry.list_tools()\n</code></pre>"},{"location":"concepts/agents/#moya.agents.base_agent.Agent.get_conversation_summary","title":"<code>get_conversation_summary(thread_id)</code>","text":"<p>Retrieve a summary of the conversation so far using the MemoryTool, if available.</p> <p>:param thread_id: The identifier of the conversation thread. :return: A textual summary of the conversation so far. If no MemoryTool          or no registry is found, returns an empty string or raises an error.</p> Source code in <code>moya/agents/base_agent.py</code> <pre><code>def get_conversation_summary(self, thread_id: str) -&gt; str:\n    \"\"\"\n    Retrieve a summary of the conversation so far using the MemoryTool, if available.\n\n    :param thread_id: The identifier of the conversation thread.\n    :return: A textual summary of the conversation so far. If no MemoryTool\n             or no registry is found, returns an empty string or raises an error.\n    \"\"\"        \n    if not self.memory:\n        return \"\"\n    return self.memory.get_conversation_summary(thread_id)\n</code></pre>"},{"location":"concepts/agents/#moya.agents.base_agent.Agent.get_last_n_messages","title":"<code>get_last_n_messages(thread_id, n=5)</code>","text":"<p>Retrieve the last n messages of the conversation using the MemoryTool, if available.</p> <p>:param thread_id: The identifier of the conversation thread. :param n: The number of recent messages to retrieve. :return: A list of message objects or dictionaries.</p> Source code in <code>moya/agents/base_agent.py</code> <pre><code>def get_last_n_messages(self, thread_id: str, n: int = 5) -&gt; List[Any]:\n    \"\"\"\n    Retrieve the last n messages of the conversation using the MemoryTool, if available.\n\n    :param thread_id: The identifier of the conversation thread.\n    :param n: The number of recent messages to retrieve.\n    :return: A list of message objects or dictionaries.\n    \"\"\"\n    if not self.memory:\n        return \"\"\n    return self.memory.get_last_n_messages(thread_id, n)\n</code></pre>"},{"location":"concepts/agents/#moya.agents.base_agent.Agent.handle_message","title":"<code>handle_message(message, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Receive a message (prompt) and generate a response.</p> <p>:param message: The user or system prompt to be handled. :param kwargs: Additional context or parameters the agent might need,                such as conversation ID, user metadata, etc. :return: The agent's response as a string.</p> Source code in <code>moya/agents/base_agent.py</code> <pre><code>@abc.abstractmethod\ndef handle_message(self, message: str, **kwargs) -&gt; str:\n    \"\"\"\n    Receive a message (prompt) and generate a response.\n\n    :param message: The user or system prompt to be handled.\n    :param kwargs: Additional context or parameters the agent might need,\n                   such as conversation ID, user metadata, etc.\n    :return: The agent's response as a string.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement handle_message().\")\n</code></pre>"},{"location":"concepts/agents/#moya.agents.base_agent.Agent.handle_message_stream","title":"<code>handle_message_stream(message, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Receive a message (prompt) and generate a response in a streaming fashion.</p> <p>:param message: The user or system prompt to be handled. :param kwargs: Additional context or parameters the agent might need,                such as conversation ID, user metadata, etc. :yield: Chunks of the agent's response as strings.</p> Source code in <code>moya/agents/base_agent.py</code> <pre><code>@abc.abstractmethod\ndef handle_message_stream(self, message: str, **kwargs):\n    \"\"\"\n    Receive a message (prompt) and generate a response in a streaming fashion.\n\n    :param message: The user or system prompt to be handled.\n    :param kwargs: Additional context or parameters the agent might need,\n                   such as conversation ID, user metadata, etc.\n    :yield: Chunks of the agent's response as strings.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement handle_message_stream().\")\n</code></pre>"},{"location":"concepts/agents/#moya.agents.base_agent.AgentConfig","title":"<code>AgentConfig</code>  <code>dataclass</code>","text":"<p>Configuration data for an agent.</p> Source code in <code>moya/agents/base_agent.py</code> <pre><code>@dataclass\nclass AgentConfig:\n    \"\"\"\n    Configuration data for an agent.\n    \"\"\"\n    agent_name: str\n    agent_type: str\n    description: str\n    system_prompt: str = \"You are a helpful AI assistant.\"\n    llm_config: Optional[Dict[str, Any]] = None\n    tool_registry: Optional[ToolRegistry] = None\n    memory: Optional[BaseMemoryRepository] = None\n    is_tool_caller: bool = False\n    is_streaming: bool = False\n\n    def __post_init__(self):\n        if not self.agent_name:\n            raise ValueError(\"Agent name must be provided.\")\n        if not self.description:\n            raise ValueError(\"Agent description must be provided.\")\n        default_llm_config = {\n                'model_name': \"default\",\n                'temperature': 0.7,\n                'max_tokens':  2000,\n                'top_p': 1.0,\n                'frequency_penalty': 0.0,\n                'presence_penalty': 0.0,\n                'stop_sequences':  [],\n        }\n        self.llm_config = {**default_llm_config, **(self.llm_config or {})}\n</code></pre>"},{"location":"concepts/agents/#openai-agent","title":"OpenAI Agent","text":""},{"location":"concepts/agents/#moya.agents.openai_agent","title":"<code>moya.agents.openai_agent</code>","text":"<p>OpenAIAgent for Moya.</p> <p>An Agent that uses OpenAI's ChatCompletion or Completion API to generate responses, pulling API key from the environment.</p>"},{"location":"concepts/agents/#moya.agents.openai_agent.OpenAIAgent","title":"<code>OpenAIAgent</code>","text":"<p>               Bases: <code>Agent</code></p> <p>A simple OpenAI-based agent that uses the ChatCompletion API.</p> Source code in <code>moya/agents/openai_agent.py</code> <pre><code>class OpenAIAgent(Agent):\n    \"\"\"\n    A simple OpenAI-based agent that uses the ChatCompletion API.\n    \"\"\"\n\n    def __init__(\n        self,\n        config: OpenAIAgentConfig   \n    ):\n        \"\"\"\n        Initialize the OpenAIAgent.\n\n        :param config: Configuration for the agent.\n        \"\"\"\n        super().__init__(config=config)\n        self.model_name = config.model_name\n        if not config.api_key:\n            raise ValueError(\"OpenAI API key is required for OpenAIAgent.\")\n        self.client = OpenAI(api_key=config.api_key)\n        self.system_prompt = config.system_prompt\n        self.tool_choice = config.tool_choice if config.tool_choice else None\n        self.max_iterations = 5\n\n    def get_tool_definitions(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Discover tools available for this agent.\n        \"\"\"\n        if not self.tool_registry:\n            return None\n\n        # Generate tool definitions for OpenAI ChatCompletion\n        tools = [\n            {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": tool.name,\n                \"description\": tool.description,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        name: {\n                            \"type\": info[\"type\"],\n                            \"description\": info[\"description\"]\n                        } for name, info in tool.parameters.items()\n                    },\n                    \"required\": [\n                        name for name, info in tool.parameters.items() \n                        if info.get(\"required\", False)\n                    ]\n                }\n            }\n        }\n        for tool in self.tool_registry.get_tools()\n        ]\n        return tools\n\n\n    def handle_message(self, message: str, **kwargs) -&gt; str:\n        \"\"\"\n        Calls OpenAI ChatCompletion to handle the user's message.\n        \"\"\"\n        return self.handle(message)\n\n    def handle_message_stream(self, message: str, **kwargs):\n        \"\"\"\n        Calls OpenAI ChatCompletion to handle the user's message with streaming support.\n        \"\"\"\n        return self.handle(message)\n\n    def handle(self, user_message: str) -&gt; str:\n        \"\"\"\n        Handle a chat session with the user and resolve tool calls iteratively.\n\n        Args:\n            user_message (str): The initial message from the user.\n\n        Returns:\n            str: Final response after tool call processing.\n        \"\"\"\n        conversation = [\n            {\"role\": \"system\", \"content\": self.system_prompt},\n            {\"role\": \"user\", \"content\": user_message}\n        ]\n        iteration = 0\n\n        while iteration &lt; self.max_iterations:\n            message = self.get_response(conversation)\n            # Extract message content\n            if isinstance(message, dict):\n                content = message.get(\"content\", \"\")\n                tool_calls = message.get(\"tool_calls\", [])\n            else:\n                content = message.content if message.content is not None else \"\"\n                tool_calls = message.tool_calls if hasattr(message, \"tool_calls\") and message.tool_calls else []\n                # Convert to list of dicts if it's not already\n                if tool_calls and not isinstance(tool_calls[0], dict):\n                    tool_calls = [tc.dict() for tc in tool_calls]\n\n            # Create assistant message entry\n            entry = {\"role\": \"assistant\", \"content\": content}\n            if tool_calls:\n                entry[\"tool_calls\"] = tool_calls\n            conversation.append(entry)\n\n            # Process tool calls if any\n            if tool_calls:\n                for tool_call in tool_calls:\n                    tool_response = self.handle_tool_call(tool_call)\n\n                    conversation.append({\n                            \"role\": \"tool\",\n                            \"tool_call_id\": tool_call.get(\"id\"),\n                            \"content\": tool_response\n                    })\n                iteration += 1\n            else:\n                break\n\n        final_message = conversation[-1].get(\"content\", \"\")\n        return final_message\n\n    def get_response(self, conversation: str) -&gt; Dict[str, Any]:\n        \"\"\"\n        Generate a response via the OpenAI ChatCompletion API with tool call support.\n\n        Args:\n            conversation (list): Current chat messages.\n\n        Returns:\n            dict: Message from the assistant, which may include 'tool_calls'.\n        \"\"\"\n\n        if self.is_streaming:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=conversation,\n                tools=self.get_tool_definitions() or None,\n                tool_choice=self.tool_choice if self.tool_registry else None,\n                stream=True\n            )\n            response_text = \"\"\n            tool_calls = []\n            current_tool_call = None\n\n            for chunk in response:\n                delta = chunk.choices[0].delta\n                if delta:\n                    if delta.content is not None:\n                        response_text += delta.content\n\n                    if delta.tool_calls:\n                        for tool_call_delta in delta.tool_calls:\n                            tool_call_index = tool_call_delta.index\n\n                            # Ensure we have enough slots in our tool_calls list\n                            while len(tool_calls) &lt;= tool_call_index:\n                                tool_calls.append({\"id\": \"\", \"type\": \"function\", \"function\": {\"name\": \"\", \"arguments\": \"\"}})\n\n                            current_tool_call = tool_calls[tool_call_index]\n\n                            # Update tool call information from this chunk\n                            if tool_call_delta.id:\n                                current_tool_call[\"id\"] = tool_call_delta.id\n\n                            if tool_call_delta.function:\n                                if tool_call_delta.function.name:\n                                    current_tool_call[\"function\"][\"name\"] = tool_call_delta.function.name\n\n                                if tool_call_delta.function.arguments:\n                                    current_tool_call[\"function\"][\"arguments\"] = (\n                                        current_tool_call[\"function\"].get(\"arguments\", \"\") + \n                                        tool_call_delta.function.arguments\n                                    )\n\n            result = {\"content\": response_text}\n            if tool_calls:\n                result[\"tool_calls\"] = tool_calls\n            return result\n        else:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=conversation,\n                tools=self.get_tool_definitions(),\n                tool_choice=self.tool_choice if self.tool_registry else None\n            )\n            message = response.choices[0].message\n\n            # Convert the response to a dict for uniform handling\n            result = {\"content\": message.content or \"\"}\n\n            if message.tool_calls:\n                # Convert tool_calls to a list of dicts\n                if isinstance(message.tool_calls, list):\n                    if not isinstance(message.tool_calls[0], dict):\n                        result[\"tool_calls\"] = [tc.dict() for tc in message.tool_calls]\n                    else:\n                        result[\"tool_calls\"] = message.tool_calls\n                else:\n                    result[\"tool_calls\"] = [message.tool_calls.dict()]\n\n            return result\n\n    def handle_tool_call(self, tool_cal: Dict[str, Any]) -&gt; str:\n        \"\"\"\n        Execute the tool specified in the tool call.\n        Implements tools: 'echo' and 'reverse'.\n\n        Args:\n            tool_call (dict): Contains 'id', 'type', and 'function' (with 'name' and 'arguments').\n\n        Returns:\n            str: The output from executing the tool.\n        \"\"\"        \n        function_data = tool_call.get(\"function\", {})\n        name = function_data.get(\"name\")\n\n        # Parse arguments if provided; they are passed as a JSON string by the API\n        import json\n        try:\n            args = json.loads(function_data.get(\"arguments\", \"{}\"))\n        except json.JSONDecodeError:\n            args = {}\n\n        tool = self.tool_registry.get_tool(name)\n        if tool:\n            try:\n                result = tool.function(**args)\n                return result\n            except TypeError:\n                return f\"[Tool '{name}' requires arguments: {tool.parameters}]\"\n            except Exception as e:\n                return f\"[Error executing tool '{name}': {str(e)}]\"\n\n        return f\"[Tool '{name}' not found]\"\n</code></pre>"},{"location":"concepts/agents/#moya.agents.openai_agent.OpenAIAgent.__init__","title":"<code>__init__(config)</code>","text":"<p>Initialize the OpenAIAgent.</p> <p>:param config: Configuration for the agent.</p> Source code in <code>moya/agents/openai_agent.py</code> <pre><code>def __init__(\n    self,\n    config: OpenAIAgentConfig   \n):\n    \"\"\"\n    Initialize the OpenAIAgent.\n\n    :param config: Configuration for the agent.\n    \"\"\"\n    super().__init__(config=config)\n    self.model_name = config.model_name\n    if not config.api_key:\n        raise ValueError(\"OpenAI API key is required for OpenAIAgent.\")\n    self.client = OpenAI(api_key=config.api_key)\n    self.system_prompt = config.system_prompt\n    self.tool_choice = config.tool_choice if config.tool_choice else None\n    self.max_iterations = 5\n</code></pre>"},{"location":"concepts/agents/#moya.agents.openai_agent.OpenAIAgent.get_response","title":"<code>get_response(conversation)</code>","text":"<p>Generate a response via the OpenAI ChatCompletion API with tool call support.</p> <p>Parameters:</p> Name Type Description Default <code>conversation</code> <code>list</code> <p>Current chat messages.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, Any]</code> <p>Message from the assistant, which may include 'tool_calls'.</p> Source code in <code>moya/agents/openai_agent.py</code> <pre><code>def get_response(self, conversation: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Generate a response via the OpenAI ChatCompletion API with tool call support.\n\n    Args:\n        conversation (list): Current chat messages.\n\n    Returns:\n        dict: Message from the assistant, which may include 'tool_calls'.\n    \"\"\"\n\n    if self.is_streaming:\n        response = self.client.chat.completions.create(\n            model=self.model_name,\n            messages=conversation,\n            tools=self.get_tool_definitions() or None,\n            tool_choice=self.tool_choice if self.tool_registry else None,\n            stream=True\n        )\n        response_text = \"\"\n        tool_calls = []\n        current_tool_call = None\n\n        for chunk in response:\n            delta = chunk.choices[0].delta\n            if delta:\n                if delta.content is not None:\n                    response_text += delta.content\n\n                if delta.tool_calls:\n                    for tool_call_delta in delta.tool_calls:\n                        tool_call_index = tool_call_delta.index\n\n                        # Ensure we have enough slots in our tool_calls list\n                        while len(tool_calls) &lt;= tool_call_index:\n                            tool_calls.append({\"id\": \"\", \"type\": \"function\", \"function\": {\"name\": \"\", \"arguments\": \"\"}})\n\n                        current_tool_call = tool_calls[tool_call_index]\n\n                        # Update tool call information from this chunk\n                        if tool_call_delta.id:\n                            current_tool_call[\"id\"] = tool_call_delta.id\n\n                        if tool_call_delta.function:\n                            if tool_call_delta.function.name:\n                                current_tool_call[\"function\"][\"name\"] = tool_call_delta.function.name\n\n                            if tool_call_delta.function.arguments:\n                                current_tool_call[\"function\"][\"arguments\"] = (\n                                    current_tool_call[\"function\"].get(\"arguments\", \"\") + \n                                    tool_call_delta.function.arguments\n                                )\n\n        result = {\"content\": response_text}\n        if tool_calls:\n            result[\"tool_calls\"] = tool_calls\n        return result\n    else:\n        response = self.client.chat.completions.create(\n            model=self.model_name,\n            messages=conversation,\n            tools=self.get_tool_definitions(),\n            tool_choice=self.tool_choice if self.tool_registry else None\n        )\n        message = response.choices[0].message\n\n        # Convert the response to a dict for uniform handling\n        result = {\"content\": message.content or \"\"}\n\n        if message.tool_calls:\n            # Convert tool_calls to a list of dicts\n            if isinstance(message.tool_calls, list):\n                if not isinstance(message.tool_calls[0], dict):\n                    result[\"tool_calls\"] = [tc.dict() for tc in message.tool_calls]\n                else:\n                    result[\"tool_calls\"] = message.tool_calls\n            else:\n                result[\"tool_calls\"] = [message.tool_calls.dict()]\n\n        return result\n</code></pre>"},{"location":"concepts/agents/#moya.agents.openai_agent.OpenAIAgent.get_tool_definitions","title":"<code>get_tool_definitions()</code>","text":"<p>Discover tools available for this agent.</p> Source code in <code>moya/agents/openai_agent.py</code> <pre><code>def get_tool_definitions(self) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Discover tools available for this agent.\n    \"\"\"\n    if not self.tool_registry:\n        return None\n\n    # Generate tool definitions for OpenAI ChatCompletion\n    tools = [\n        {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": tool.name,\n            \"description\": tool.description,\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    name: {\n                        \"type\": info[\"type\"],\n                        \"description\": info[\"description\"]\n                    } for name, info in tool.parameters.items()\n                },\n                \"required\": [\n                    name for name, info in tool.parameters.items() \n                    if info.get(\"required\", False)\n                ]\n            }\n        }\n    }\n    for tool in self.tool_registry.get_tools()\n    ]\n    return tools\n</code></pre>"},{"location":"concepts/agents/#moya.agents.openai_agent.OpenAIAgent.handle","title":"<code>handle(user_message)</code>","text":"<p>Handle a chat session with the user and resolve tool calls iteratively.</p> <p>Parameters:</p> Name Type Description Default <code>user_message</code> <code>str</code> <p>The initial message from the user.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Final response after tool call processing.</p> Source code in <code>moya/agents/openai_agent.py</code> <pre><code>def handle(self, user_message: str) -&gt; str:\n    \"\"\"\n    Handle a chat session with the user and resolve tool calls iteratively.\n\n    Args:\n        user_message (str): The initial message from the user.\n\n    Returns:\n        str: Final response after tool call processing.\n    \"\"\"\n    conversation = [\n        {\"role\": \"system\", \"content\": self.system_prompt},\n        {\"role\": \"user\", \"content\": user_message}\n    ]\n    iteration = 0\n\n    while iteration &lt; self.max_iterations:\n        message = self.get_response(conversation)\n        # Extract message content\n        if isinstance(message, dict):\n            content = message.get(\"content\", \"\")\n            tool_calls = message.get(\"tool_calls\", [])\n        else:\n            content = message.content if message.content is not None else \"\"\n            tool_calls = message.tool_calls if hasattr(message, \"tool_calls\") and message.tool_calls else []\n            # Convert to list of dicts if it's not already\n            if tool_calls and not isinstance(tool_calls[0], dict):\n                tool_calls = [tc.dict() for tc in tool_calls]\n\n        # Create assistant message entry\n        entry = {\"role\": \"assistant\", \"content\": content}\n        if tool_calls:\n            entry[\"tool_calls\"] = tool_calls\n        conversation.append(entry)\n\n        # Process tool calls if any\n        if tool_calls:\n            for tool_call in tool_calls:\n                tool_response = self.handle_tool_call(tool_call)\n\n                conversation.append({\n                        \"role\": \"tool\",\n                        \"tool_call_id\": tool_call.get(\"id\"),\n                        \"content\": tool_response\n                })\n            iteration += 1\n        else:\n            break\n\n    final_message = conversation[-1].get(\"content\", \"\")\n    return final_message\n</code></pre>"},{"location":"concepts/agents/#moya.agents.openai_agent.OpenAIAgent.handle_message","title":"<code>handle_message(message, **kwargs)</code>","text":"<p>Calls OpenAI ChatCompletion to handle the user's message.</p> Source code in <code>moya/agents/openai_agent.py</code> <pre><code>def handle_message(self, message: str, **kwargs) -&gt; str:\n    \"\"\"\n    Calls OpenAI ChatCompletion to handle the user's message.\n    \"\"\"\n    return self.handle(message)\n</code></pre>"},{"location":"concepts/agents/#moya.agents.openai_agent.OpenAIAgent.handle_message_stream","title":"<code>handle_message_stream(message, **kwargs)</code>","text":"<p>Calls OpenAI ChatCompletion to handle the user's message with streaming support.</p> Source code in <code>moya/agents/openai_agent.py</code> <pre><code>def handle_message_stream(self, message: str, **kwargs):\n    \"\"\"\n    Calls OpenAI ChatCompletion to handle the user's message with streaming support.\n    \"\"\"\n    return self.handle(message)\n</code></pre>"},{"location":"concepts/agents/#moya.agents.openai_agent.OpenAIAgent.handle_tool_call","title":"<code>handle_tool_call(tool_cal)</code>","text":"<p>Execute the tool specified in the tool call. Implements tools: 'echo' and 'reverse'.</p> <p>Parameters:</p> Name Type Description Default <code>tool_call</code> <code>dict</code> <p>Contains 'id', 'type', and 'function' (with 'name' and 'arguments').</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The output from executing the tool.</p> Source code in <code>moya/agents/openai_agent.py</code> <pre><code>def handle_tool_call(self, tool_cal: Dict[str, Any]) -&gt; str:\n    \"\"\"\n    Execute the tool specified in the tool call.\n    Implements tools: 'echo' and 'reverse'.\n\n    Args:\n        tool_call (dict): Contains 'id', 'type', and 'function' (with 'name' and 'arguments').\n\n    Returns:\n        str: The output from executing the tool.\n    \"\"\"        \n    function_data = tool_call.get(\"function\", {})\n    name = function_data.get(\"name\")\n\n    # Parse arguments if provided; they are passed as a JSON string by the API\n    import json\n    try:\n        args = json.loads(function_data.get(\"arguments\", \"{}\"))\n    except json.JSONDecodeError:\n        args = {}\n\n    tool = self.tool_registry.get_tool(name)\n    if tool:\n        try:\n            result = tool.function(**args)\n            return result\n        except TypeError:\n            return f\"[Tool '{name}' requires arguments: {tool.parameters}]\"\n        except Exception as e:\n            return f\"[Error executing tool '{name}': {str(e)}]\"\n\n    return f\"[Tool '{name}' not found]\"\n</code></pre>"},{"location":"concepts/agents/#moya.agents.openai_agent.OpenAIAgentConfig","title":"<code>OpenAIAgentConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AgentConfig</code></p> <p>Configuration data for an OpenAIAgent.</p> Source code in <code>moya/agents/openai_agent.py</code> <pre><code>@dataclass\nclass OpenAIAgentConfig(AgentConfig):\n    \"\"\"\n    Configuration data for an OpenAIAgent.\n    \"\"\"\n    model_name: str = \"gpt-4o\"\n    api_key: str = None\n    tool_choice: Optional[str] = None\n</code></pre>"},{"location":"examples/basic/","title":"Basic Examples","text":"<p>Placeholder content</p>"}]}